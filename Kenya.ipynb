{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevint2007/solarstressindez/blob/main/Kenya.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSsbYg0EIkVS"
      },
      "outputs": [],
      "source": [
        "!pip install geemap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5icx9jbJBKD"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import geemap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-U7v8A0yJPoc"
      },
      "outputs": [],
      "source": [
        "\n",
        "PROJECT_ID = 'hi' # @param {type:\"string\"}\n",
        "if not PROJECT_ID:\n",
        "    raise ValueError(\"Please enter your own Google Cloud Project ID in the field above before running this cell.\")\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project=PROJECT_ID)\n",
        "\n",
        "print(f\"Successfully initialized Earth Engine with project: {PROJECT_ID}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrJS9t17KbqX"
      },
      "outputs": [],
      "source": [
        "Map = geemap.Map()\n",
        "Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5J6uApqfAhIO"
      },
      "outputs": [],
      "source": [
        "# --- Phase 0: Define Your 5 Clusters ---\n",
        "\n",
        "# 1. Define the 5 Center Points (Lat/Lon estimated from your map)\n",
        "# Format: [Longitude, Latitude]\n",
        "eldoret_point = ee.Geometry.Point([35.2698, 0.5143])   # Cluster 1: Eldoret\n",
        "embu_point    = ee.Geometry.Point([37.4500, -0.5300])  # Cluster 2: Embu\n",
        "tsavo_point   = ee.Geometry.Point([38.5500, -3.4000])  # Cluster 3: The \"Giant\" (Voi/Taita)\n",
        "kilifi_point  = ee.Geometry.Point([39.8500, -3.6300])  # Cluster 4: Mombasa North\n",
        "kwale_point   = ee.Geometry.Point([39.4500, -4.1800])  # Cluster 5: Mombasa South\n",
        "\n",
        "# 2. Create \"Market Areas\" (10km Radius buffers around points)\n",
        "# We do this so we aren't just analyzing a single pixel, but the whole town.\n",
        "cluster_1 = eldoret_point.buffer(10000)\n",
        "cluster_2 = embu_point.buffer(10000)\n",
        "cluster_3 = tsavo_point.buffer(10000)\n",
        "cluster_4 = kilifi_point.buffer(10000)\n",
        "cluster_5 = kwale_point.buffer(10000)\n",
        "\n",
        "# 3. Combine them into a single \"Feature Collection\" (Like a Shapefile)\n",
        "my_clusters = ee.FeatureCollection([\n",
        "    ee.Feature(cluster_1, {'name': 'Eldoret_Cluster'}),\n",
        "    ee.Feature(cluster_2, {'name': 'Embu_Cluster'}),\n",
        "    ee.Feature(cluster_3, {'name': 'Tsavo_Cluster'}),\n",
        "    ee.Feature(cluster_4, {'name': 'Mombasa_North'}),\n",
        "    ee.Feature(cluster_5, {'name': 'Mombasa_South'})\n",
        "])\n",
        "\n",
        "# 4. Add them to the map to verify\n",
        "# We paint them RED to match your Project 1 design\n",
        "Map.centerObject(my_clusters, 7)\n",
        "Map.addLayer(my_clusters, {'color': 'red'}, 'My 5 Priority Clusters')\n",
        "\n",
        "# 5. Display the map\n",
        "Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ7WtLWpkDj0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "# Setup the Time Range (3 Years of Data)\n",
        "start_date = '2021-01-01'\n",
        "end_date = '2023-12-31'\n",
        "\n",
        "# 2. Define the Sentinel-2 Collection\n",
        "def get_clean_s2(roi):\n",
        "    s2 = (ee.ImageCollection('COPERNICUS/S2_SR')\n",
        "          .filterDate(start_date, end_date)\n",
        "          .filterBounds(roi)\n",
        "          .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))\n",
        "          # Add a 'date' property to every image so we can track it later\n",
        "          .map(lambda img: img.set('date', img.date().format('YYYY-MM-dd'))))\n",
        "    return s2\n",
        "\n",
        "# 3. Define the Function to Calculate NDVI & Extract Mean Value\n",
        "def add_ndvi_and_reduce(img):\n",
        "    # Calculate NDVI: (NIR - Red) / (NIR + Red)\n",
        "    ndvi = img.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
        "\n",
        "    # Calculate the MEAN NDVI inside the clusters\n",
        "    # We use 'reduceRegions' to calculate statistics for ALL 5 clusters at once\n",
        "    stats = ndvi.reduceRegions(\n",
        "        collection=my_clusters,\n",
        "        reducer=ee.Reducer.mean(),\n",
        "        scale=100  # 100m scale is faster and sufficient for regional trends\n",
        "    )\n",
        "\n",
        "    # The result is a FeatureCollection. We attach the image date to every row.\n",
        "    return stats.map(lambda f: f.set('date', img.date().format('YYYY-MM-dd')))\n",
        "\n",
        "# 4. Run the Pipeline (This sends the instruction to Google)\n",
        "print(\"Querying Google Earth Engine... (This might take 45-60 seconds)\")\n",
        "\n",
        "# Get the images\n",
        "s2_collection = get_clean_s2(my_clusters.geometry())\n",
        "\n",
        "# Apply the math to every image and flatten the result into one big list\n",
        "all_stats = s2_collection.map(add_ndvi_and_reduce).flatten()\n",
        "\n",
        "# 5. Convert to Pandas DataFrame (The \"Download\" step)\n",
        "# FIXED: used 'ee_to_df' instead of the old 'ee_to_pandas'\n",
        "df = geemap.ee_to_df(all_stats)\n",
        "\n",
        "# 6. Clean and Inspect the Data\n",
        "# Select only the columns we need\n",
        "df = df[['date', 'mean', 'name']]\n",
        "\n",
        "# Convert the 'date' column to datetime objects\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df = df.sort_values('date')\n",
        "df = df.dropna() # Remove empty rows\n",
        "\n",
        "print(\"Success! Data Extracted.\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Phase 2: Visualizing the \"Solar Stress Index\" ---\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Setup the Plot Style\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "plt.figure(figsize=(14, 7))\n",
        "\n",
        "# 2. Draw the Lines (One color per Cluster)\n",
        "# 'hue' automatically separates your 5 clusters into different colors\n",
        "sns.lineplot(data=df, x='date', y='mean', hue='name', linewidth=2, alpha=0.8)\n",
        "\n",
        "# 3. Add the \"Danger Zone\" Line\n",
        "# NDVI < 0.3 usually indicates bare soil or extreme drought\n",
        "plt.axhline(y=0.3, color='red', linestyle='--', linewidth=2, label='Critical Stress Threshold (0.3)')\n",
        "\n",
        "# 4. Polish the Chart labels\n",
        "plt.title('Agricultural Resilience (NDVI) - 2021 to 2023', fontsize=16, fontweight='bold')\n",
        "plt.ylabel('Vegetation Health (Proxy for Income)', fontsize=12)\n",
        "plt.xlabel('Date', fontsize=12)\n",
        "plt.legend(title='Cluster Location', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "\n",
        "# 5. Show it\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6h1okvNxf8tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rainfall(roi):\n",
        "    chirps = (ee.ImageCollection('UCSB-CHG/CHIRPS/PENTAD')\n",
        "              .filterDate(start_date, end_date)\n",
        "              .filterBounds(roi))\n",
        "    return chirps\n",
        "\n",
        "def calc_rainfall(img):\n",
        "    # CHIRPS has a band called 'precipitation'\n",
        "    # We calculate the MEAN rainfall in the cluster (mm per 5 days)\n",
        "    # scale=5000 is CRITICAL because CHIRPS pixels are 5km wide\n",
        "    stats = img.reduceRegions(\n",
        "        collection=my_clusters,\n",
        "        reducer=ee.Reducer.mean(),\n",
        "        scale=5000\n",
        "    )\n",
        "    return stats.map(lambda f: f.set('date', img.date().format('YYYY-MM-dd')))\n",
        "\n",
        "rain_collection = get_rainfall(my_clusters.geometry())\n",
        "rain_stats = rain_collection.map(calc_rainfall).flatten()\n",
        "\n",
        "# 4. Convert to Pandas\n",
        "# Uses the updated geemap syntax\n",
        "df_rain = geemap.ee_to_df(rain_stats)\n",
        "\n",
        "# 5. Clean Data\n",
        "df_rain = df_rain[['date', 'mean', 'name']]\n",
        "df_rain['date'] = pd.to_datetime(df_rain['date'])\n",
        "df_rain = df_rain.sort_values('date')\n",
        "\n",
        "# 6. Visualize Rain vs. Vegetation\n",
        "# We focus on TSAVO (The \"Crash\" Cluster) to see the correlation\n",
        "target_cluster = 'Tsavo_Cluster'\n",
        "\n",
        "# Filter data for just Tsavo\n",
        "tsavo_ndvi = df[df['name'] == target_cluster]\n",
        "tsavo_rain = df_rain[df_rain['name'] == target_cluster]\n",
        "\n",
        "# Plotting (Dual Axis)\n",
        "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "# Plot Rainfall (Bars) on Left Axis\n",
        "color = 'tab:blue'\n",
        "ax1.set_xlabel('Date')\n",
        "ax1.set_ylabel('Rainfall (mm)', color=color)\n",
        "ax1.bar(tsavo_rain['date'], tsavo_rain['mean'], color=color, alpha=0.3, label='Rainfall', width=5)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "# Plot NDVI (Line) on Right Axis\n",
        "ax2 = ax1.twinx()  # Instantiate a second axes that shares the same x-axis\n",
        "color = 'tab:red'\n",
        "ax2.set_ylabel('Vegetation Health (NDVI)', color=color)\n",
        "ax2.plot(tsavo_ndvi['date'], tsavo_ndvi['mean'], color=color, linewidth=3, label='Vegetation (NDVI)')\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "ax2.axhline(y=0.3, color='black', linestyle='--', label='Stress Threshold')\n",
        "\n",
        "plt.title(f'The \"Lag Effect\": Rain vs. Income in {target_cluster}', fontsize=16)\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rVLT4nKki6-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Phase 3: Merging the Data for Machine Learning ---\n",
        "\n",
        "# 1. Prepare the Tables\n",
        "# We rename columns so they don't conflict (e.g., 'mean' -> 'NDVI', 'mean' -> 'Rain')\n",
        "ndvi_clean = df.rename(columns={'mean': 'NDVI'})[['date', 'name', 'NDVI']]\n",
        "rain_clean = df_rain.rename(columns={'mean': 'Rain'})[['date', 'name', 'Rain']]\n",
        "\n",
        "# 2. Merge them on 'Date' and 'Name'\n",
        "# This aligns the Rain and Vegetation for the same day and location\n",
        "master_df = pd.merge_asof(\n",
        "    ndvi_clean.sort_values('date'),\n",
        "    rain_clean.sort_values('date'),\n",
        "    on='date',\n",
        "    by='name',\n",
        "    direction='nearest', # Match the closest rainfall reading to the satellite photo\n",
        "    tolerance=pd.Timedelta('5 days') # Allow a 5-day window match\n",
        ")\n",
        "\n",
        "# 3. Handle Missing Data\n",
        "master_df = master_df.dropna()\n",
        "\n",
        "print(\"Success! Master Dataset Created.\")\n",
        "print(master_df.head())"
      ],
      "metadata": {
        "id": "ZvddCGdEmbcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Phase 4.3: Experiment B - The \"Reality Check\" (Temporal Split) ---\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# (Assuming Steps 0, 1, and 2 from your previous code are already run,\n",
        "# meaning `cluster_data` is defined and sorted by date)\n",
        "\n",
        "# 1. Define the Cutoff Date for the \"Black Swan\" Event\n",
        "# We train on everything BEFORE 2022, and test on 2022 onwards\n",
        "cutoff_date = pd.to_datetime('2022-01-01')\n",
        "\n",
        "# 2. Split the Data Chronologically (NO random splitting)\n",
        "train_data = cluster_data[cluster_data['date'] < cutoff_date]\n",
        "test_data = cluster_data[cluster_data['date'] >= cutoff_date]\n",
        "\n",
        "# 3. Define Features & Target for both sets\n",
        "features = ['Past_30d_Rain_Avg', 'Prev_NDVI', 'Month']\n",
        "\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['NDVI']\n",
        "\n",
        "X_test = test_data[features]\n",
        "y_test = test_data['NDVI']\n",
        "\n",
        "# 4. Train Random Forest (Strictly on Past Data)\n",
        "model = RandomForestRegressor(n_estimators=100, max_depth=7, random_state=42)\n",
        "model.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# 5. Predict & Score (Testing on the Unknown Future)\n",
        "y_pred = model.predict(X_test)\n",
        "score = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"--- EXPERIMENT B: THE PLOT TWIST (Temporal Split) ---\")\n",
        "print(f\"Training Period: {train_data['date'].min().date()} to {train_data['date'].max().date()}\")\n",
        "print(f\"Testing Period:  {test_data['date'].min().date()} to {test_data['date'].max().date()}\")\n",
        "print(f\"RÂ² Score: {score:.3f}\")\n",
        "# Expected Result: A negative number (Model is worse than guessing the historical average)\n",
        "\n",
        "# 6. Visualize the Failure for the Medium Article (Figure 3)\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Plot Actual vs Predicted using actual Dates on the X-axis\n",
        "plt.plot(test_data['date'], y_test, label='Actual NDVI (The Collapse)', color='tab:green', linewidth=2.5)\n",
        "plt.plot(test_data['date'], y_pred, label='Predicted NDVI (Model Guess)', color='tab:red', linestyle='--', linewidth=2.5)\n",
        "\n",
        "# Add the 0.3 Stress Threshold line for visual context\n",
        "plt.axhline(y=0.3, color='black', linestyle=':', linewidth=2, label='Stress Threshold (0.3)')\n",
        "\n",
        "plt.title(f'The Plot Twist: Model Failure During 2022-2023 Drought ({target_cluster})', fontsize=16)\n",
        "plt.xlabel('Date', fontsize=12)\n",
        "plt.ylabel('Vegetation Health (NDVI)', fontsize=12)\n",
        "plt.legend(loc='lower left', fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Use tight_layout so it exports perfectly for Medium\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot locally to upload to Medium\n",
        "plt.savefig('temporal_split_failure.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uImMRnmBpoAY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdJs3iVmiyOwRsVPb/yv8e",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}